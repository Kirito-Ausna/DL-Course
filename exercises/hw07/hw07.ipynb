{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Train MLP and CNN on MNIST for 10-class feature extraction and classification\n",
    "Please implement the following three functions:\n",
    "- MnistMLP() - Design a 2-layer MLP\n",
    "- MnistCNN() - Design a 2-layer CNN \n",
    "\n",
    "Please train a 2-layer MLP and CNN on the Mnist dataset and print the training results for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose,ToTensor,Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    " \n",
    "BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 1000\n",
    "\n",
    "# dataloader for the dataset\n",
    "def get_dataloader(train,batch_size=BATCH_SIZE):\n",
    "    transform_fn = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean = (0.1307,),std = (0.3081,))\n",
    "        ]) \n",
    "    dataset = MNIST(root = './data',train = train,transform = transform_fn, download = True)\n",
    "    data_loader = DataLoader(dataset,batch_size = batch_size,shuffle = True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-lyer MLP \n",
    "class MnistMLP(nn.Module):\n",
    "    # implement a 2-layer MLP with 256 hidden units\n",
    "    def __init__(self):\n",
    "        super(MnistMLP,self).__init__()\n",
    "        self.fc1 = nn.Linear(784,256)\n",
    "        self.fc2 = nn.Linear(256,10)\n",
    "       \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-lyer CNN\n",
    "class MnistCNN(nn.Module):\n",
    "    # implement a 2-layer CNN with 32 hidden units\n",
    "    def __init__(self):\n",
    "        super(MnistCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,32,5)\n",
    "        self.conv2 = nn.Conv2d(32,64,5)\n",
    "        self.fc1 = nn.Linear(1024,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = x.view(-1,1024)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistMLP()\n",
    "optimizer = Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, num_epochs):\n",
    "    data_loader = get_dataloader(True)\n",
    "    total_step = len(data_loader)\n",
    "    for idx, (input,target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (idx+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, idx+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    test_dataloader = get_dataloader(train = False,batch_size=TEST_BATCH_SIZE)\n",
    "    for idx,(input,target) in enumerate(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            output = model(input)\n",
    "            cur_loss = F.nll_loss(output,target)\n",
    "            loss_list.append(cur_loss)\n",
    "            pred = output.max(dim = -1)[-1]\n",
    "            cur_acc = pred.eq(target).float().mean()\n",
    "            acc_list.append(cur_acc)\n",
    "    print(\"Mean accuracy：\",np.mean(acc_list),\"Mean loss：\",np.mean(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaadc7530975489c9ae00013766a1e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b86c45d18bf456cbbe1b5f6285f0017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f516de4f10c467fae1c6ccac11e78e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0248617e344e4fb0a0d94db5e0b661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/SAO/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-pma2oi4d/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy： 0.13280001 Mean loss： 0.047826394\n",
      "Epoch [1/3], Step [100/469], Loss: -1337.5470\n",
      "Epoch [1/3], Step [200/469], Loss: -6875.2241\n",
      "Epoch [1/3], Step [300/469], Loss: -18192.4336\n",
      "Epoch [1/3], Step [400/469], Loss: -31483.2109\n",
      "Epoch [2/3], Step [100/469], Loss: -66548.0625\n",
      "Epoch [2/3], Step [200/469], Loss: -92688.9531\n",
      "Epoch [2/3], Step [300/469], Loss: -121390.2656\n",
      "Epoch [2/3], Step [400/469], Loss: -151889.6562\n",
      "Epoch [3/3], Step [100/469], Loss: -217582.9062\n",
      "Epoch [3/3], Step [200/469], Loss: -266575.4375\n",
      "Epoch [3/3], Step [300/469], Loss: -304110.8750\n",
      "Epoch [3/3], Step [400/469], Loss: -349140.0625\n",
      "Mean accuracy： 0.1028 Mean loss： -397532.84\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "num_epochs = 3\n",
    "for i in range(num_epochs):\n",
    "    train(i, num_epochs)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistCNN()\n",
    "optimizer = Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/SAO/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-pma2oi4d/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy： 0.1003 Mean loss： 0.1282757\n",
      "Epoch [1/3], Step [100/469], Loss: -47170.9414\n",
      "Epoch [1/3], Step [200/469], Loss: -639579.0000\n",
      "Epoch [1/3], Step [300/469], Loss: -2566493.5000\n",
      "Epoch [1/3], Step [400/469], Loss: -6714652.5000\n",
      "Epoch [2/3], Step [100/469], Loss: -21581188.0000\n",
      "Epoch [2/3], Step [200/469], Loss: -35664700.0000\n",
      "Epoch [2/3], Step [300/469], Loss: -52052776.0000\n",
      "Epoch [2/3], Step [400/469], Loss: -79147312.0000\n",
      "Epoch [3/3], Step [100/469], Loss: -127857608.0000\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "num_epochs = 3\n",
    "for i in range(num_epochs):\n",
    "    train(i, num_epochs)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
